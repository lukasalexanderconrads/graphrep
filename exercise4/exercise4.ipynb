{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 The Message Passing Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Graph Neural Networks\n",
    "Consider the ogbn-arxiv graph. Implement a Basic GNN (slide 8) using your message passing framework code from the previous exercise sheet. Ignore the training by backpropagation, for now, by proceeding as follows:\n",
    "\n",
    "Initialize $r_0(v)$ = v[′attr′] by using the 128-dimensional attribute vectors.\n",
    "\n",
    "For k ∈ {0,1,2,3} create random matrices $W^{self}_k ,W^{neigh}_k ∈ [−1,1]^{d_k×d_{k+1}}$ and\n",
    "random bias vectors $b_k ∈[−1,1]^{d_{k+1}}$. Choose the dimensionalities $d_k$, resp. $d_{k+1}$,\n",
    "appropriately.\n",
    "\n",
    "Use a nonlinearity function σ of your choice.\n",
    "\n",
    "For each k ∈{0,1,2,3}, perform a node classification based on vertex representations\n",
    "$r_k$ using a simple logistic regression classifier w.r.t. the target attribute label. Plot the\n",
    "accuracy scores over k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import math as m\n",
    "\n",
    "def update_f(wself,wneigh,bias,old_feature_v,update_value):\n",
    "    s1 = wself.dot(old_feature_v)\n",
    "    s2 = wneigh.dot(update_value)  \n",
    "    s3 = s1+s2+bias\n",
    "    return tanh_vec(s3)\n",
    "def aggregation_f(array):\n",
    "    return np.sum(array,axis=0)\n",
    "\n",
    "def msg_passing(wself,wneigh,bias,g,current_feature_rep,runs): #note that we need to change this if we want to input only a subgraph\n",
    "    curr_r = np.copy(current_feature_rep)\n",
    "    #assume that the initial feature representation spans the whole graph\n",
    "    #get neighbors ONCE\n",
    "        #neighborhood(vertices=None, order=1, mode='all', mindist=0): \n",
    "        #mindist = 1: exclude seed node\n",
    "    neighbors=g.neighborhood(vertices=None,order=1,mode='all',mindist=1)\n",
    "    #print(neighbors)\n",
    "    results = [curr_r]\n",
    "    for i in np.arange(runs): \n",
    "        print(\"run\",i)\n",
    "        next_r = np.empty_like(curr_r)\n",
    "        for idx,n in enumerate(curr_r):\n",
    "            #fetch the attributes out of the current representation array\n",
    "            neigh_attr = np.take(curr_r, neighbors[idx],axis=0)\n",
    "            #aggregate the attributes of the neighbors\n",
    "            aggregate = aggregation_f(neigh_attr)\n",
    "            #update the current representation\n",
    "            update = update_f(wself[i,:,:],wneigh[i,:,:],bias[i,:],current_feature_rep[idx].T,aggregate)\n",
    "            next_r[idx] = update\n",
    "        curr_r = next_r\n",
    "        results.append(next_r)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169343, 128)\n"
     ]
    }
   ],
   "source": [
    "#read graph and initialize r0 as v['attr']\n",
    "g = ig.Graph.Read_Pickle('ogbn-arxiv.pickle').as_undirected()\n",
    "init_feature_rep = np.array([v['attr'] for v in g.vs()])\n",
    "print(init_feature_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create matrices (per k)and bias \n",
    "k = np.array([0,1,2,3])\n",
    "dk = 128 #???\n",
    "\n",
    "np.random.seed(seed=3)\n",
    "wself = np.array((2*np.random.random_sample((len(k),dk,dk))-1)) #interval [-1,1) - better way to do it??\n",
    "wneigh = np.array((2*np.random.random_sample((len(k),dk,dk))-1)) #interval [-1,1)\n",
    "bias = np.array((2*np.random.random_sample((len(k),dk))-1)) #interval [-1,1)\n",
    "\n",
    "#use \"tanh\" as sigma\n",
    "def tanhf(z):\n",
    "    return m.tanh(z)\n",
    "\n",
    "tanh_vec = np.vectorize(tanhf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0\n",
      "run 1\n",
      "run 2\n",
      "run 3\n",
      "Run time: 81.66237400000045 s\n"
     ]
    }
   ],
   "source": [
    "runs=len(k)\n",
    "t1 = timeit.default_timer()\n",
    "result = msg_passing(wself,wneigh,bias,g,init_feature_rep,runs)\n",
    "result_array = np.asarray(result)\n",
    "rtime = timeit.default_timer() - t1\n",
    "print(\"Run time:\", rtime,\"s\")\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwibc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mwibc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mwibc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 103.71406109999953 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwibc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression(random_state=3,max_iter=100,solver=\"lbfgs\")\n",
    "t1 = timeit.default_timer()\n",
    "score = np.empty_like(k,dtype=float)\n",
    "y = np.array(g.vs['label'])\n",
    "\n",
    "for idx,k_value in enumerate(k):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(result_array[k_value], y, test_size=0.33, random_state=42)\n",
    "    lr.fit(x_train,y_train.ravel())\n",
    "    score[idx] = lr.score(x_test,y_test)\n",
    "train_time = timeit.default_timer() - t1\n",
    "#print(score)\n",
    "print(\"Train time:\", train_time,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: [0 1 2 3]\n",
      "Accuracy: [0.54588075 0.57154105 0.58199127 0.56091189]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"k:\",k)\n",
    "print(\"Accuracy:\", score)\n",
    "plt.figure()\n",
    "plt.scatter(k,score)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"accuracy score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Degree Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again consider the ogbn-arxiv graph. Implement two Basic GNNs A,B (slide 8) using your message passing framework code from the previous exercise sheet. Ignore the training by backpropagation, for now, by proceeding as follows:\n",
    "\n",
    "•Initialize r0(v) = 1 ∈R100, i.e., to the 100-dimensional vector of ones.\n",
    "\n",
    "•For k ∈ {0,1,2,3} create random matrices $W^{self}_k ,W^{neigh}_k ∈ [−1,1]^{100×100}$ and\n",
    "random bias vectors $b_k ∈[−1,1]^100$.\n",
    "\n",
    "•Use a nonlinearity function σ of your choice.\n",
    "\n",
    "•For GNN A use the sum aggregator (i.e., don’t change the formula on slide 8).\n",
    "\n",
    "•For GNN B, use the mean aggregator, i.e., set $r_{k+1}(v) = σ(W^{self}_k*r_k(v) + W^{neigh}_k*\\frac{1}{|N(v)|}*\\sum_{w\\in N(v)}r_k(w)+b_k)$\n",
    "\n",
    "For each k ∈{0,1,2,3}, perform a node regression task based on vertex representations\n",
    "rk using a simple linear regression. This time choose the node degrees as target labels.\n",
    "Plot the accuracy scores over k. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 PyTorch Geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Geometric or PYG is a framework for graph neural networks on top of PyTorch.\n",
    "It already implements GINs, GCNs and quite a lot of other GNN variants.\n",
    "Implement the neural network architecture presented on slide 24 for both GINs and GCNs using PYG for the node classification task on the cora graph. You may follow the tutorial of PYG that conveniently shows how to implement a GCN layer for this graph.\n",
    "Implement three GIN, resp. GCN, layers and add a fully connected layer to transform your representations r3 to the expected input of the softmax function.\n",
    "Split your test data into 30% validation and 70% test. Evaluate the accuracy of your model after each epoch on the validation data and plot the accuracy over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
