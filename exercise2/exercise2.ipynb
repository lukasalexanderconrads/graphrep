{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Counting paths in graphlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import igraph as ig\n",
    "\n",
    "#create the depicted graphs unter 1.2)\n",
    "g1 = ig.Graph()\n",
    "g1.add_vertices(4)\n",
    "g1.add_edges([(0,1),(1,2),(1,3),(2,3)])\n",
    "#print(g1)\n",
    "\n",
    "g2 = ig.Graph()\n",
    "g2.add_vertices(4)\n",
    "g2.add_edges([(0,1),(1,2),(1,3),(2,3),(0,3)])\n",
    "#print(g2)\n",
    "\n",
    "g3 = ig.Graph()\n",
    "g3.add_vertices(5)\n",
    "g3.add_edges([(0,2),(0,3),(1,2),(2,3),(3,4),(1,4)])\n",
    "#print(g3)\n",
    "\n",
    "g4 = ig.Graph()\n",
    "g4.add_vertices(5)\n",
    "g4.add_edges([(0,4),(1,4),(1,3),(1,2),(2,3),(3,4)])\n",
    "#print(g4)\n",
    "\n",
    "g5 = ig.Graph()\n",
    "g5.add_vertices(5)\n",
    "g5.add_edges([(0,1),(1,2),(2,3),(3,4),(4,0),(0,2),(2,4),(1,3)])\n",
    "#print(g5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1)\n",
    "#implement DFS\n",
    "def init_algo(g):\n",
    "    #for every start node, span a new directed tree and sum the count of \"complete\" paths \n",
    "    sum = 0\n",
    "    for v in g.vs:\n",
    "        c = ig.Graph() #create a new empty graph c\n",
    "        c.to_directed() \n",
    "        n = 0\n",
    "        c.add_vertices(1) #add the baase vertex\n",
    "        c.vs[n]['num']=v.index #label it the its index in graph g\n",
    "        count_paths(g,c,n)\n",
    "        \n",
    "        #get the in-neighboorhood (order = #node if graph g) of each node in graph c and store it in an array.\n",
    "        #where we have a size of the neighborhood = the node count of graph g: we know that this path connect all nodes\n",
    "        res = np.where(np.array([len(v) for v in c.neighborhood(c.vs,order=g1.vcount(),mode='in')]) == g1.vcount(),1,0)\n",
    "        sum += np.sum(res) #get only those \"complete\" paths \n",
    "    return sum\n",
    "    \n",
    "def count_paths(g,c,n): \n",
    "    #get all predecessors of the current lastly added node and get their labels (not indices!)\n",
    "    pred = c.neighborhood(c.vs[n],order=g.vcount(),mode=\"in\")\n",
    "    pred = np.array([c.vs[v]['num'] for v in pred])\n",
    "    #for each neighbor of the current node in g check whether it was already part of the new path in c.\n",
    "    for neigh in g.neighbors(g.vs[c.vs[n]['num']]):\n",
    "        cut = False   \n",
    "        if neigh in pred: #if it was in the path in c already, cut branch\n",
    "            cut = True\n",
    "        if not cut: #otherwise, add it as a new node with the correct label and continue with its neighbors in graph g\n",
    "            c.add_vertices(1)\n",
    "            c.add_edges([(n,c.vcount()-1)])        \n",
    "            c.vs[c.vcount()-1]['num'] = neigh\n",
    "            count_paths(g,c,c.vcount()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g1 path count:  4\n",
      "g2 path count:  12\n",
      "g3 path count:  20\n",
      "g4 path count:  20\n",
      "g5 path count:  56\n"
     ]
    }
   ],
   "source": [
    "#1.2\n",
    "#count possible paths:\n",
    "count = init_algo(g1)\n",
    "print(\"g1 path count: \",count)\n",
    "\n",
    "count = init_algo(g2)\n",
    "print(\"g2 path count: \",count)\n",
    "\n",
    "count = init_algo(g3)\n",
    "print(\"g3 path count: \",count)\n",
    "\n",
    "count = init_algo(g4)\n",
    "print(\"g4 path count: \",count)\n",
    "\n",
    "count = init_algo(g5)\n",
    "print(\"g5 path count: \",count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Sampled harmonic closeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# load the graph as undirected\n",
    "g = ig.Graph.Read_Pickle('ogbn-arxiv.pickle').as_undirected()\n",
    "subg_idx = np.array([v.index for v in g.vs.select(label_eq=12)])\n",
    "alpha = np.array([0.001,0.01,0.1,1])\n",
    "alpha = np.array([0.001])\n",
    "runs = 30\n",
    "runs = 1\n",
    "\n",
    "## I assume he meant slide 40???\n",
    "#2.1\n",
    "def SCC(landmarks,g,vidx):\n",
    "    wdist=0\n",
    "    for mark in landmarks:\n",
    "        #print(\"l: \",mark)\n",
    "        if mark!=v:\n",
    "            spath = g.get_shortest_paths(g.vs[vidx], to=g.vs[mark], weights=None, mode='all', output='epath') #indices are those of edges!!\n",
    "            #print(spath, \"- \", len(spath[0]))\n",
    "            wdist+=1/len(spath[0])\n",
    "    Cl=1/(np.size(landmarks))*wdist\n",
    "    return Cl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base:  0 - run:  0 -  0.18355426624657387\n",
      "base:  1 - run:  0 -  0.17235136658213576\n",
      "base:  2 - run:  0 -  0.19512069127453735\n",
      "base:  3 - run:  0 -  0.12333854508410712\n",
      "base:  4 - run:  0 -  0.16708526516218813\n",
      "base:  5 - run:  0 -  0.15718533603148974\n",
      "base:  6 - run:  0 -  0.16421783344860266\n",
      "base:  7 - run:  0 -  0.15630011014626388\n",
      "base:  8 - run:  0 -  0.16818608741685656\n",
      "base:  9 - run:  0 -  0.10424581992629321\n",
      "base:  10 - run:  0 -  0.21387971003355616\n",
      "base:  11 - run:  0 -  0.1550511454357607\n",
      "base:  12 - run:  0 -  0.1647906170095518\n",
      "base:  13 - run:  0 -  0.13016349199781138\n",
      "base:  14 - run:  0 -  0.1305019766558227\n",
      "base:  15 - run:  0 -  0.1814362987439909\n",
      "base:  16 - run:  0 -  0.160565995477238\n",
      "base:  17 - run:  0 -  0.20708650324034933\n",
      "base:  18 - run:  0 -  0.24073938881631204\n",
      "base:  19 - run:  0 -  0.1549708838170376\n",
      "base:  20 - run:  0 -  0.1153733265419655\n",
      "base:  21 - run:  0 -  0.17467169582554187\n",
      "base:  22 - run:  0 -  0.13685203685203676\n",
      "base:  23 - run:  0 -  0.12946419129851067\n",
      "base:  24 - run:  0 -  0.1361772842542072\n",
      "base:  25 - run:  0 -  0.16933451164220384\n",
      "base:  26 - run:  0 -  0.16619256811564503\n",
      "base:  27 - run:  0 -  0.18109326570865023\n",
      "base:  28 - run:  0 -  0.1311266314224893\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#2.2\n",
    "result = np.zeros((np.size(alpha),np.size(subg_idx),runs))\n",
    "for idx, a in enumerate(alpha):\n",
    "    #select #random landmarks given alpha\n",
    "    nodes_L = int(alpha[0]*len(g.vs)) #just convert float to int\n",
    "    #print(nodes_L)\n",
    "    #print(range(0, len(g.vs)-1))\n",
    "    for vidx, v in enumerate(subg_idx):\n",
    "        #print(\"basis: \",vidx, \"-\" ,v)\n",
    "        for r in np.arange(0,runs):\n",
    "            #select random landmark node indices - part of graph G \n",
    "            landmarks = random.sample(range(0,len(g.vs)-1), nodes_L)\n",
    "            #Make sure V is not in landmarks (else one node would be missing)\n",
    "            while vidx in landmarks:\n",
    "                landmarks = random.sample(range(0,len(g.vs)-1), nodes_L)\n",
    "            \n",
    "            #print(\"landmarks: \",landmarks[0:5])\n",
    "            res = SCC(landmarks,g,v)\n",
    "            print(\"base: \",vidx,\"- run: \",r, \"- \",res)\n",
    "            result[idx,vidx,r-1] = res\n",
    "print(\"done\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.001\n",
      "Mean:  [0.18355427 0.17235137 0.19512069 0.12333855 0.16708527 0.15718534\n",
      " 0.16421783 0.15630011 0.16818609 0.10424582 0.21387971 0.15505115\n",
      " 0.16479062 0.13016349 0.13050198 0.1814363  0.160566   0.2070865\n",
      " 0.24073939 0.15497088 0.11537333 0.1746717  0.13685204 0.12946419\n",
      " 0.13617728 0.16933451 0.16619257 0.18109327 0.13112663]\n",
      "Std:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# get mean and standard deviation for each alpha\n",
    "for idx, a in enumerate(alpha):\n",
    "    mean = np.array([np.mean(result[idx,e,:]) for e,_ in enumerate(subg_idx)])\n",
    "    std = np.array([np.std(result[idx,e,:]) for e,_ in enumerate(subg_idx)])\n",
    "    print(\"alpha: \",a)\n",
    "    print(\"Mean: \",mean)\n",
    "    print(\"Std: \",std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Degeneracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the graph as undirected\n",
    "g = igraph.Graph.Read_Pickle('ogbn-arxiv.pickle').as_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degeneracy(g):\n",
    "    # get adjacency list\n",
    "    adj = g.get_adjlist()\n",
    "    # create result array\n",
    "    deg = np.zeros((g.vcount()))\n",
    "    # create A\n",
    "    arrA = [[] for _ in range(g.vcount())]\n",
    "    # create B and init with degreee of each vertex\n",
    "    arrB = g.degree(range(g.vcount()))\n",
    "    # fill A with lists of vertices that have each degree\n",
    "    for i, degree in enumerate(arrB):\n",
    "        arrA[degree].append(i)\n",
    "    \n",
    "    # loop over all degrees \n",
    "    k = d_min = 0        \n",
    "    while d_min < g.vcount():\n",
    "        # if there are no vertices with degree d_min, consider d_min + 1\n",
    "        if arrA[d_min] == []:\n",
    "            d_min += 1\n",
    "        # otherwise, consider a vertex with degree d_min\n",
    "        else:\n",
    "            # remove the vertex from A\n",
    "            vertex = arrA[d_min].pop()\n",
    "            # for each neighbor of A\n",
    "            for neigh in adj[vertex]:\n",
    "                # find its degree\n",
    "                neigh_degree = arrB[neigh]\n",
    "                # move the neighbor in A to its new degree list\n",
    "                arrA[neigh_degree].remove(neigh)\n",
    "                arrA[neigh_degree - 1].append(neigh)\n",
    "                # decrease its degree in B\n",
    "                arrB[neigh] -= 1\n",
    "                # remove vertex from the adjacency list of its neighbor\n",
    "                adj[neigh].remove(vertex)\n",
    "            # compute the coreness of the vertex\n",
    "            k = max(k, d_min)\n",
    "            deg[vertex] = k\n",
    "            # decrease d_min to consider possible ex-neighbors of vertex\n",
    "            d_min -= 1\n",
    "            \n",
    "    return deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = degeneracy(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implementation is correct: True\n"
     ]
    }
   ],
   "source": [
    "# check if implementation gives the correct result\n",
    "is_correct = np.all(np.equal(deg, g.coreness()))\n",
    "print(f'implementation is correct: {is_correct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
